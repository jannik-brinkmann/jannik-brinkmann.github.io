<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=EB+Garamond:ital,wght@0,400..800;1,400..800&family=Open+Sans:ital,wght@0,300..800;1,300..800&family=Poppins:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap" rel="stylesheet">
    <title>Jannik Brinkmann</title>
    <link rel="stylesheet" type="text/css" href="assets/css/style.css">
</head>
<body>

  <header class="hero">
    <div class="container">
      <h1>Jannik Brinkmann</h1>
      <div class="abstract">
        <p>
          I am a Ph.D. student advised by <a>Christian Bartelt</a>.
          I am also affiliated with the <a href="https://baulab.info">interpretable neural networks group</a> at Northeastern University led by <a href="https://scholar.google.com/citations?user=CYI6cKgAAAAJ&hl=en">David Bau</a>. 
          I spent the winter semester 2024/2025 as a visiting researcher in the <a href="https://wp.nyu.edu/ml2/">ML<sup>2</sup></a> research group at NYU advised by <a href="https://cds.nyu.edu/team/he-he/">He He</a>.
          I interned at J.P. Morgan Research working on post-training of language models for mathematical reasoning.
        </p>
        <div class="profile-links">
          <a href="https://scholar.google.com/citations?user=YtdTeaMAAAAJ&hl=en" class="button pill">Google Scholar</a>
          <a href="https://github.com/jannik-brinkmann" class="button pill">GitHub</a>
          <a href="publications.html" class="button pill">Publication List</a>
        </div>
      </div>
    </div>
  </header>

  <main class="container">

    <h2>Research</h2>

    I am interested in the structure and interpretation of natural and artificial systems. In the past, I studied mechanisms of multi-step reasoning in transformers, cross-lingual feature sharing in language models, and sparse autoencoders as a tool for interpreting language model representations. Beyond understanding models themselves, I am excited about the prospect of discovering useful knowledge in them and teaching it to humans.

    <h3>Selected Publications</h3>
    <ol>
      <li>
        <p class="text"><a href="https://arxiv.org/abs/2602.06020">Mechanisms of Protein Folding in ESMFold.</a></p>
      </li>
      <li>
        <p class="text"><a href="https://aclanthology.org/2025.naacl-long.312/">Large Language Models Share Representations of Latent Grammatical Concepts across Typologically Diverse Languages</a>. Nations of the Americas Chapter of the Association for Computational Linguistics (NAACL), 2025. <b>(Oral)</b></p>
      </li>
      <li>
        <p class="text"><a href="https://aclanthology.org/2024.findings-acl.242/">A Mechanistic Analysis of a Transformer Trained on a Symbolic Multi-Step Reasoning Task</a>. Association for Computational Linguistics (ACL), 2024.</p>
      </li>
    </ol>
  </main>
</body>
</html>
